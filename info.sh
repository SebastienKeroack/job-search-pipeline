#!/bin/bash
#                                  MIT License
#                       Copyright 2026, Sébastien Kéroack
# ==============================================================================

set -euo pipefail

# ==============================================================================
# == n8n

# Activate n8n community edition license
# And enter license key received via email after registering on first launch
echo "Access n8n at: http://localhost:5678"
echo "Activate n8n community edition license at: http://localhost:5678/settings/usage"
echo "Register to receive a free community edition license key."
echo

# Resources:
# - https://www.youtube.com/watch?v=LIzZRgfW4ok
# - https://hub.docker.com/r/n8nio/n8n
# - https://hub.docker.com/r/n8nio/runners
# - https://docs.n8n.io/hosting/installation/docker/#prerequisites
# - https://docs.n8n.io/hosting/configuration/task-runners/#1-extend-the-n8niorunners-image
# - https://github.com/n8n-io/n8n/issues/11886
# - https://github.com/Piggeldi2013/n8n-timeout-patch/tree/main

# ==============================================================================
# == Google OAuth2 Single Service - n8n integration

# Set up Google Cloud project and enable APIs:
echo https://console.cloud.google.com/
echo "Create project with name: $GOOGLE_PROJECT_NAME"
echo "Note down the Project ID generated."
echo "e.g.,"
echo "Project ID: <$GOOGLE_PROJECT_ID> (auto-generated by Google Cloud)"
echo

# APIs to enable:
echo https://console.cloud.google.com/apis/library?project=$GOOGLE_PROJECT_ID
echo "Enable the following APIs:"
echo "- Google Drive API"
echo "- Google Sheets"
echo

# Setup Branding information:
echo https://console.cloud.google.com/auth/branding?project=$GOOGLE_PROJECT_ID
echo "Set the following information:"
echo "- App name: $GOOGLE_APP_NAME"
echo "- User support email: $GOOGLE_EMAIL"
echo "- Developer contact information: $GOOGLE_EMAIL"
echo "[Save]"
echo

# Credentials to create (OAuth 2.0 Client IDs):
echo https://console.cloud.google.com/apis/credentials?project=$GOOGLE_PROJECT_ID
echo "Create OAuth 2.0 Client ID with the following information:"
echo "- Application type: Web application"
echo "- Name: $GOOGLE_APP_AUTH_NAME"
echo "- Authorized redirect URIs: http://localhost:5678/rest/oauth2-credential/callback"
echo "[Create]"
echo "Note down the Client ID and Client secret generated."
echo "e.g.,"
echo "- Client ID: $GOOGLE_APP_AUTH_CLIENT_ID"
echo "- Client secret: $GOOGLE_APP_AUTH_CLIENT_SECRET"
echo

# Add ourself as test users (Publishing status: Testing):
echo https://console.cloud.google.com/auth/audience?project=$GOOGLE_PROJECT_ID
echo "[+ Add users]: Add the following test user:"
echo "- $GOOGLE_EMAIL"
echo "[Save]"
echo

# Resources:
# - https://docs.n8n.io/integrations/builtin/credentials/google/oauth-single-service
# - https://console.cloud.google.com/auth/library
# - https://console.cloud.google.com/auth/branding
# - https://console.cloud.google.com/auth/credentials
# - https://console.cloud.google.com/auth/audience

# ==============================================================================
# == Ollama (local LLM server)

# CPU only
: '
docker run -d \
  --network job-search-pipeline-net \
  --name ollama \
  -p 11434:11434 \
  -e OLLAMA_MAX_LOADED_MODELS=$OLLAMA_MAX_LOADED_MODELS \
  -e OLLAMA_CONTEXT_LENGTH=$OLLAMA_CONTEXT_LENGTH \
  -e OLLAMA_KEEP_ALIVE=$OLLAMA_KEEP_ALIVE \
  -e OLLAMA_LOAD_TIMEOUT=$OLLAMA_LOAD_TIMEOUT \
  -e OLLAMA_NOHISTORY=$OLLAMA_NOHISTORY \
  -v "$OLLAMA_HOME:/root/.ollama" \
  ollama/ollama:$OLLAMA_VERSION
'
# GPU (NVIDIA)
: '
# More prerequisites are needed, see:
# - https://hub.docker.com/r/ollama/ollama
# After installing the required toolkit, run:
docker run -d \
  --gpus all \
  --ipc host \
  --ulimit memlock=-1 \
  --ulimit stack=67108864 \
  --network job-search-pipeline-net \
  --name ollama \
  -p 11434:11434 \
  -e OLLAMA_MAX_LOADED_MODELS=$OLLAMA_MAX_LOADED_MODELS \
  -e OLLAMA_CONTEXT_LENGTH=$OLLAMA_CONTEXT_LENGTH \
  -e OLLAMA_KEEP_ALIVE=$OLLAMA_KEEP_ALIVE \
  -e OLLAMA_LOAD_TIMEOUT=$OLLAMA_LOAD_TIMEOUT \
  -e OLLAMA_NOHISTORY=$OLLAMA_NOHISTORY \
  -v /home/ollama:/root/.ollama \
  ollama/ollama:$OLLAMA_VERSION
'
# GPU (ROCM)
: '
docker run -d \
  --device /dev/kfd \
  --device /dev/dri \
  --network job-search-pipeline-net \
  --name ollama \
  -p 11434:11434 \
  -e OLLAMA_MAX_LOADED_MODELS=$OLLAMA_MAX_LOADED_MODELS \
  -e OLLAMA_CONTEXT_LENGTH=$OLLAMA_CONTEXT_LENGTH \
  -e OLLAMA_KEEP_ALIVE=$OLLAMA_KEEP_ALIVE \
  -e OLLAMA_LOAD_TIMEOUT=$OLLAMA_LOAD_TIMEOUT \
  -e OLLAMA_NOHISTORY=$OLLAMA_NOHISTORY \
  -v /home/ollama:/root/.ollama \
  ollama/ollama:$OLLAMA_VERSION-rocm
'
echo "Check Ollama logs with:"
echo "      docker logs ollama"
echo

#| Model Name                | RAM Requirement | Context Length |
#|---------------------------|-----------------|----------------|
#| deepseek-r1:1.5b          | 3GB             | N/A            |
#| gpt-oss:20b               | 14GB            | 128K           |
#| gpt-oss:120b              | 65GB            | 128K           |
#| nemotron-3-nano:30b       | 24GB            | 1M             |
#docker exec -it ollama ollama run $OLLAMA_MODEL "" # <-- "" indicates an empty prompt to preload the model
# To set temperature for a model:
# $ /set parameter temperature 0.5
# To set number of threads for a model:
# $ /set parameter num_thread 14
# To see available parameters for a model:
# $ /set parameter

# Resources:
# - https://hub.docker.com/r/ollama/ollama
# - https://github.com/ollama/ollama/blob/main/docs/faq.mdx
# - https://github.com/ollama/ollama/blob/main/envconfig/config.go
# - https://ollama.com/library/gpt-oss
# - https://ollama.com/library/nemotron-3-nano

# ==============================================================================
# == Ollama - n8n integration

# Resources:
# - https://docs.n8n.io/integrations/builtin/credentials/ollama/?utm_source=n8n_app&utm_medium=credential_settings&utm_campaign=create_new_credentials_modal#using-instance-url
# - https://json-schema.org/learn/miscellaneous-examples#basic

# ==============================================================================
# == Final notes

echo "n8n is running and accessible at http://localhost:5678"
echo "  and http://n8n:5678 for containers on the job-search-pipeline-net network"
echo
echo "Ollama is running and accessible at http://localhost:11434"
echo "  and http://ollama:11434 for containers on the job-search-pipeline-net network"
echo
echo "Monitor containers with:"
echo "      docker stats job-search-pipeline ollama"
echo
